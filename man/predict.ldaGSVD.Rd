% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ldaGSVD.R
\name{predict.ldaGSVD}
\alias{predict.ldaGSVD}
\title{Predictions from a fitted ldaGSVD object}
\usage{
\method{predict}{ldaGSVD}(object, newdata, type = c("response", "prob"))
}
\arguments{
\item{type}{}
}
\description{
Prediction of test data using ldaGSVD.
}
\details{
Unlike the original paper, which uses the k-nearest neighbor (k-NN) as the
classifier, we use a faster and more straightforward likelihood-based method.
One limitation of the traditional likelihood-based method for LDA is that it
ceases to work when there are Linear Discriminant (LD) directions with zero
variance in the within-class scatter matrix. However, when using LDA/GSVD,
all chosen LD directions possess non-zero variance in the between-class
scatter matrix. This implies that LD directions with zero variance in the
within-class scatter matrix will yield the highest Fisher's ratio. Therefore,
to get these directions higher weights, we manually adjust the zero variance
to `1e-5` for computational reasons.
}
\references{
Ye, J., Janardan, R., Park, C. H., & Park, H. (2004). \emph{An
  optimization criterion for generalized discriminant analysis on
  undersampled problems}. IEEE Transactions on Pattern Analysis and Machine
  Intelligence

  Howland, P., Jeon, M., & Park, H. (2003). \emph{Structure preserving dimension
  reduction for clustered text data based on the generalized singular value
  decomposition}. SIAM Journal on Matrix Analysis and Applications
}
